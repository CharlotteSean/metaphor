# Shared Task on Metaphor Detection


This repository contains the dataset used in the [shared task on metaphor detection](https://competitions.codalab.org/competitions/17805) in the [First Workshop on Figurative Language Processing](https://sites.google.com/site/figlangworkshop/), co-located with NAACL 2018. We provide a script to parse VUAMC.xml, the main dataset used in the competition, a set of features used to construct the baseline classification model for prediction of metaphor/non-metaphor classes at the word level, and instructions on how to replicate our published results. As additional information, we also provide software specifications used to generate our baseline feature types and values.

Main Dataset
---------
Our features are obtained by extraction, parsing and tagging of the [VU Amsterdam Metaphor Corpus](http://ota.ahds.ac.uk/headers/2541.xml) using this set of [software](https://github.com/EducationalTestingService/metaphor/tree/master/content-words#software). While replicating our results does not require repeating the above processes on the dataset, you will need to download a copy of the dataset to extract any additional features. There are altogether 117 texts covering four genres (academic, conversation, fiction, news).

Task Details
---------
You can either participate in the metaphor prediction task for verbs only, all part-of-speech only, or both.

Parsing VUAMC.XML for additional features
---------
To participate in the shared tasks, you can either use our baseline feature sets as a starting point, or generate your own feature sets by parsing the original VUAMC.xml.

To parse the VUAMC.xml, first download the [VUAMC.xml zip file](http://ota.ahds.ac.uk/text/2541.zip), then unzip it. You should get the file `2541/VUAMC.xml`. After that, run the following command (in Python 3.x):

```
python vua_xml_parser.py
```

This will generate `vuamc_corpus.csv` with 16203 lines in the following format:

```
"txt_id","sentence_id","sentence_txt"
"a1e-fragment01","1","Latest corporate unbundler M_reveals laid-back M_approach : Roland Franklin , who is M_leading a 697m pound break-up bid for DRG , talks M_to Frank Kane"
"a1e-fragment01","2","By FRANK KANE"
"a1e-fragment01","3","IT SEEMS that Roland Franklin , the latest unbundler to appear in the UK , has M_made a M_fatal error M_in the preparation of his £697m break-up bid for stationery and packaging group DRG ."
"a1e-fragment01","4","He has not properly investigated the M_target 's dining facilities ."
"a1e-fragment01","5","The 63-year-old M_head of Pembridge Investments , M_through which the bid is being M_mounted says , ‘ M_rule number one M_in M_this business is : the more luxurious the luncheon rooms at M_headquarters , the more inefficient the business ’ ."
"a1e-fragment01","6","If he had M_taken his own rule seriously , he would have found out that DRG has a very M_modest self-service canteen at its Bristol M_head office ."
"a1e-fragment01","7","There are other M_things he has , M_on his own M_admission , not fully investigated , like the value of the DRG properties , or which M_part of the DRG business he would M_keep M_after the break up ."
...
```

The `txt_id` is the ID of each text provided in the VUAMC.xml, `sentence_id` is the ID of the sentence within a given text. Any token marked with `M_` denotes a metaphor, while the lack of which denotes a non-metaphor.


Data Interpretation
---------
In our baseline feature sets, each token has a <b>unique</b> identifier across the entire corpus. For example, the token ID `a1e-fragment01_1_4_reveals` denotes text `a1e-fragment01`, sentence `1`, word offset `4`. To cross-reference this token ID in vuamc_corpus.csv (generated by you), simply tokenize the corresponding sentence using whitespace and count starting from the first word. Include all token types (word, punct) in your count. In this case, `M_reveals` is found as the 4th token in the tokenized list below, constituting a match.

```
>>> "Latest corporate unbundler M_reveals laid-back M_approach : Roland Franklin , who is M_leading a 697m pound break-up bid for DRG , talks M_to Frank Kane".split()
['Latest', 'corporate', 'unbundler', 'M_reveals', 'laid-back', 'M_approach', ':', 'Roland', 'Franklin', ',', 'who', 'is', 'M_leading', 'a', '697m', 'pound', 'break-up', 'bid', 'for', 'DRG', ',', 'talks', 'M_to', 'Frank', 'Kane']
```

Again, only <b>verbs</b> and <b>content words</b> determined by us are considered in the evaluation of the shared task submissions. While you have the full sentences for each text in vuamc_corpus.csv, please generate predictions only for those covered in the datasets.

Result Submission
---------
When submitting results for evaluation in the share tasks, you will be asked to provide a listing of the token ID (minus the tailing word) and the predictions (0 for non-metaphor, 1 for metaphor). For example, a submission for the verbs-only track would look like this:

```
...
a1e-fragment01_1_4,1
a1e-fragment01_1_13,1
a1e-fragment01_11_5,1
a1e-fragment01_12_3,1
a1e-fragment01_12_21,0
a1e-fragment01_12_33,1
...
```

Replication of our baseline results
---------
For the shared task, you are welcome to use any machine/deep learning toolkit to generate predictions for each target token. In our baseline experiments, we used the logistic classifier in [SKLL v1.5](https://github.com/EducationalTestingService/skll). We provided a set of training and testing data that are subsets from the `news` genre as a walkthrough example.

SKLL can be installed via Conda. You can find installation instructions for [conda](https://github.com/conda/conda)

Next, run
```
# create a conda environment with python 3.6
>conda create -n naacl_flp python=3.6

# activate the conda environment
>source activate naccl_flp
```

Install SKLL v1.5
```
(naacl_flp)>conda install -c desilinguist skll
```

Run the example
```
(naacl_flp)>export SKLL_MAX_CONCURRENT_PROCESSES=1
(naacl_flp)>run_experiment toy_set.cfg
```

Once the experiment is completed, you should be able to look into `results` directory and get approximately the following confusion matrix:

```
+---+------+-----+-----------+--------+-----------+
|   |    0 |   1 | Precision | Recall | F-measure |
+---+------+-----+-----------+--------+-----------+
| 0 | [74] |   9 |     0.851 |  0.892 |     0.871 |
+---+------+-----+-----------+--------+-----------+
| 1 |   13 | [4] |     0.308 |  0.235 |     0.267 |
+---+------+-----+-----------+--------+-----------+

```

Reference Paper
---------
[Semantic Classifications for Detection of Verb Metaphors](http://aclweb.org/anthology/P/P16/P16-2017.pdf)
([erratum](paper/metaphor_acl_2016_erratum.pdf))
Beata Beigman Klebanov, Ben Leong, E. Dario Gutierrez, Ekaterina Shutova and Michael Flor, in Proceedings of the 54th Meeting of the Association for Computational Linguistics (ACL), 2016

[Supervised Word-Level Metaphor Detection: Experiments with Concreteness and Reweighting of Examples](https://aclweb.org/anthology/W/W15/W15-1402.pdf)
Beata Beigman Klebanov, Ben Leong, Michael Flor,
in Proceedings of the Third Workshop on Metaphor in NLP (Meta4NLP), Denver, CO, 2015


Related Papers
---------
[Different Texts, Same Metaphors: Unigrams and Beyond](http://anthology.aclweb.org/W/W14/W14-2302.pdf)
Beata Beigman Klebanov, Ben Leong, Michael Heilman and Michael Flor,
in Proceedings of the Second Workshop on Metaphor in NLP (Meta4NLP), Baltimore, MD, 2014


